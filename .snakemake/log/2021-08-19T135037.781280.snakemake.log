Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job stats:
job       count    min threads    max threads
------  -------  -------------  -------------
all           1              1              1
export        1              1              1
refine        1              1              1
traits        1              1              1
total         4              1              1

Select jobs to execute...

[Thu Aug 19 13:50:38 2021]
rule refine:
    input: results/tree_raw.nwk, data/background.tsv, data/reference.fasta
    output: results/tree.nwk, results/branch_lengths.json
    jobid: 2
    resources: tmpdir=/var/folders/0k/d2dh04j55mbgzhttclt2by640000gp/T

[Thu Aug 19 13:50:40 2021]
Error in rule refine:
    jobid: 2
    output: results/tree.nwk, results/branch_lengths.json
    shell:
        
        augur refine --tree results/tree_raw.nwk             --vcf-reference data/reference.fasta             --metadata data/background.tsv             --timetree             --root min_dev             --coalescent opt             --output-tree results/tree.nwk             --output-node-data results/branch_lengths.json
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /Users/naomi.rankin/sampling_bias/.snakemake/log/2021-08-19T135037.781280.snakemake.log
